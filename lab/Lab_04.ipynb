{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\" style=\"border-style: hidden\" class=\"table\"> <tr><td class=\"col-md-2\"><img style=\"float\" src=\"http://prob140.org/assets/icon256.png\" alt=\"Prob140 Logo\" style=\"width: 120px;\"/></td><td><div align=\"left\"><h3 style=\"margin-top: 0;\">Probability for Data Science</h3><h4 style=\"margin-top: 20px;\">UC Berkeley, Fall 2020</h4><p>Ani Adhikari and Jim Pitman</p>CC BY-NC 4.0</div></td></tr></table><!-- not in pdf -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "from prob140 import *\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Lab 4: Decisions Based on Ranks #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "In Data 8 you developed ways to decide whether two numerical samples come from the same underlying distribution. One approach was to combine the two samples and observe that if the samples were drawn from the same distribution, then each one should look like random draws from the combined sample.\n",
    "\n",
    "In this lab you will study a variation of this approach that is useful when you are trying to decide between the following hypotheses about one of the samples. \n",
    "- **Null**: The sample looks like a simple random sample drawn from the combined data.\n",
    "- **Alternative**: The data in the sample are in general smaller than the data in the other sample.\n",
    "\n",
    "Suppose there are $n$ elements in your sample and $m$ elements in the other sample. Let $N = n+m$ denote the size of the combined sample. The method is based on *ranking* all $N$ elements of the combined sample with the convention that Rank 1 is the smallest and Rank $N$ the largest. \n",
    "\n",
    "For now, set aside details such as how to rank elements that are equal. Focus on the main idea:\n",
    "- If the data in your sample look like a simple random sample from the combined data, then the ranks in your sample should look like a simple random sample of size $n$ drawn from $\\{1, 2, 3, \\ldots, N\\}$.\n",
    "- If the data in your sample are in general smaller than the data in the other sample, then the ranks in your sample should in general be lower than a simple random sample of ranks.\n",
    "\n",
    "So the method compares the ranks in your sample with a simple random sample drawn from the first $N$ positive integers. \n",
    "\n",
    "If it seems as though this throws away the data and just retains the ranks, that's true but not harmful for several reasons:\n",
    "- If you are trying to decide between the two hypotheses stated above, then you care about whether elements are bigger or smaller than each other, but not about exactly how big they are; so ranks are all you need.\n",
    "- The method is easy to use for small samples as well as large, and does not require assumptions about the distribution of the combined sample.\n",
    "- The method works pretty well compared to methods that do depend on assumptions about the underlying distributions.\n",
    "- Ranks are not affected by outliers.\n",
    "\n",
    "Besides, sometimes all you have are ranks. For example, you may have a ranking of candidates for admission but no single numerical measure that leads to the ranks. You can use the methods of this lab to compare the ranks of two categories of applicants.\n",
    "\n",
    "What you will learn about in this lab:\n",
    "- Settings in which it makes more sense to use ranks than the original data\n",
    "- How to use Python to rank data\n",
    "- A useful statistic based on ranks\n",
    "- How to find the exact distribution of the statistic when the sample size is small\n",
    "- How to work with the normal curve in Python\n",
    "- The normal approximation to the distribution of the statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Instructions\n",
    "Your labs have two components: a written portion and a portion that also involves code. Written work should be completed on paper, and coding questions should be done in the notebook. You are welcome to LaTeX your answers to the written portions, but staff will not be able to assist you with LaTeX related issues. It is your responsibility to ensure that both components of the lab are submitted completely and properly to Gradescope. Refer to the bottom of the notebook for submission instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage\n",
    "## Part 1: Ranks ##\n",
    "We will develop the method by revisiting Deflategate, a storm in the world of American football and a topic familiar to us from Data 8.\n",
    "\n",
    "Here are some extracts from the Data 8 textbook:\n",
    "\n",
    ">On January 18, 2015, the Indianapolis Colts and the New England Patriots played the American Football Conference (AFC) championship game to determine which of those teams would play in the Super Bowl. After the game, there were allegations that the Patriots' footballs had not been inflated as much as the regulations required; they were softer. This could be an advantage, as softer balls might be easier to catch ...\n",
    "\n",
    ">At half-time, all the game balls were collected for inspection. Two officials, Clete Blakeman and Dyrol Prioleau, measured the pressure in each of the balls. \n",
    "\n",
    ">Here are the data. Each row corresponds to one football. Pressure is measured in psi [pounds per square inch]. The Patriots ball that had been intercepted by the Colts was not inspected at half-time. Nor were most of the Colts' balls â€“ the officials simply ran out of time and had to relinquish the balls for the start of second half play.\n",
    "\n",
    "Each team had 12 footballs. Eleven of the Patriots' footballs were measured, and four of the Colts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "football = Table.read_table('Lab04_data/deflategate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "football.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "It is clear that the Patriots' footballs had less pressure than the Colts'. But that is not a fair comparison since the two sets of footballs started out at different pressures: all the Patriots' footballs at 12.5 psi and the Colts' at 13 psi, both levels allowed by NFL regulations. \n",
    "\n",
    "Pressure drops naturally during the game. The variable of interest, therefore, is the amount by which the pressure dropped. The Colts' allegation can be politely restated as saying that the drops in pressure among the Patriots' footballs were so large that something unusual had to have happened."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1a) Drop in Pressure ###\n",
    "Based on each of the columns `Blakeman` and `Prioleau`, calculate the drop in pressure for each football. Start by creating an array of the 15 starting values of pressure. Remember that `np.ones(n)` evaluates to an array of $n$ 1's, and `np.append(array_1, array_2)` evaluates to an array that appends `array_2` to `array_1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "start = ...\n",
    "\n",
    "blakeman_drops = start - ...\n",
    "prioleau_drops = start - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below and confirm a few of the drop values by mental math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "drops = football.drop(1, 2).with_columns(\n",
    "    'Blakeman', blakeman_drops,\n",
    "    'Prioleau', prioleau_drops\n",
    ")\n",
    "\n",
    "drops.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1b) Ranking the Data ###\n",
    "It does look as though the pressure drop among the Colts' footballs was less than that among the Patriots'. To examine this further, we have to first figure out how to deal with the fact that the two officials' measurements were different from each other.\n",
    "\n",
    "Since we are just interested in the ordering of the drops and not their values, it's a good idea to look at ranks and see how the two officials' rankings compare.\n",
    "\n",
    "The `stats` function `rankdata` takes a numerical array as its argument and returns the array of ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "data_1 = make_array(27, 32, 28, 35, 25)\n",
    "stats.rankdata(data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "When we use rank-based methods we do have to face the issue of \"ties,\" that is, data values that are equal. For what we are going to do in this lab, it doesn't matter how you rank tied values. We ask that you rank ties by using the `method = 'ordinal'` option of `rankdata`. It assigns distinct ranks to all the values, assigning consecutive ranks to equal values in the order in which they appear in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "data_2 = np.append(data_1, 32 * np.ones(3))\n",
    "data_2, stats.rankdata(data_2, method = 'ordinal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use `rankdata` with the `method = 'ordinal'` option to rank Blakeman's drop values, and, separately, Prioleau's drop values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "blakeman_ranks = stats.rankdata(...)\n",
    "prioleau_ranks = stats.rankdata(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Look at the ranks below and do a quick mental check of a few of them for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "drops = drops.with_columns(\n",
    "    'Blakeman Ranks', blakeman_ranks,\n",
    "    'Prioleau Ranks', prioleau_ranks\n",
    ")\n",
    "\n",
    "drops.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1c) Consistency of Ranks ###\n",
    "In which columns is it easier to compare consistency and inconstency between the two officials: the ranks or the drop values? What consistencies and inconsistencies do you notice when you compare the ranks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage\n",
    "\n",
    "## Part 2: Wilcoxon's Rank Sum Statistic ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Is the difference due to chance? More precisely, the question is whether the Colts' ranks are like a simple random sample of all 15 ranks or whether the Colts' ranks are generally smaller than the Patriots'. If the Colts' ranks are smaller, then it means that the pressure in the Patriots' footballs dropped by more than can be explained by random chance. That is what the Colts were alleging. \n",
    "\n",
    "In fact, the Colts were alleging even more, which is that the increased drop was deliberate. We can't assess that. But we can see whether the the Colts' ranks are generally too low to be explained by chance.\n",
    "\n",
    "It is now time to quantify \"ranks are generally too low\". We will do this by using the **[Wilcoxon](https://en.wikipedia.org/wiki/Frank_Wilcoxon) Rank Sum statistic**, which is just the sum of the Colts' ranks. A low rank sum corresponds to the Colts' ranks being \"generally low\". In general, the Wilcoxon rank sum statistic is the sum of the ranks of one of the two samples.\n",
    "\n",
    "It is important to keep in mind that we are not interested in which of the Colts' footballs received which rank; we are just interested in the set of ranks received by those balls. That is, we are interested in an unordered sample of 4 out of the 15 ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2a) Blakeman's Rank Sum ###\n",
    "What is the rank sum statistic based on Blakeman's ranks? That is, what is the sum of the Colts' ranks as assigned by Blakeman?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "How many sets of four can be formed from among the numbers 1 through 15? Remember that `special.comb(n, k)` evaluates to ${n \\choose k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "total_samples = ...\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "What is the smallest possible sum that you can get from a subset of four numbers from chosen from the integers 1 through 15? How many subsets have this sum? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Based on the value of Blakeman's rank sum, should you conclude that the Colts' ranks are like a random sample of four ranks? Explain briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2b) Prioleau's Rank Sum ###\n",
    "Now turn to Prioleau's ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "prioleau = drops.select(0, 4)\n",
    "prioleau.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "You can of course calculate Prioleau's rank sum mentally, but for further applications it is useful to be able to do this using Python.\n",
    "\n",
    "Use `group` to find Prioleau's rank sum for both teams. Refer to the [Data 8 Python reference](http://data8.org/sp18/python-reference.html) if necessary. The table `both_sums` should contain both the rank sums, and `prioleau_colts_sum` should be the observed value of Prioleau's statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "both_sums = ...group...\n",
    "prioleau_colts_sum = ...item...\n",
    "\n",
    "both_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use the cell below to show why the total of all the ranks is 120. Fill in the comment as an explanation, and then compute the sum **not by brute force but by using an appropriate formula that can easily be applied when the sample is larger.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "# The total of the ranks is the sum of ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2c) All Possible Rank Sums ###\n",
    "The `combinations` function of `itertools` has been imported and is used below to display all the subsets of 4 out the 15 ranks. These are all the possible samples of ranks that the Colts' could have. Check that the table has the right number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "population = np.arange(1, 16)\n",
    "\n",
    "all_samples = Table().with_column(\n",
    "    'Ranks', list(combinations(population, 4))\n",
    ")\n",
    "\n",
    "all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Construct an array `rank_sums` consisting of the sums of the ranks in all the samples, and augment the table `all_samples` with a column `Rank Sum` containing the rank sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "rank_sums = ...\n",
    "\n",
    "all_samples = ...\n",
    "\n",
    "all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2d) Probability Distribution of the Rank Sum ###\n",
    "What is the smallest and largest the rank sum can be? You should not need to use `sort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "smallest = ...\n",
    "largest = ...\n",
    "\n",
    "smallest, largest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Draw a histogram of the rank sums, using bins of width 1 centered on each possible value of the rank sum. As this histogram is based on every possible sample, it displays the *sampling distribution* or equivalently the exact probability distribution of the rank sum statistic under the null hypothesis of random selection.\n",
    "\n",
    "Note that you will need to offset your bins by 0.5 to ensure that the bars are centered properly.\n",
    "\n",
    "The additional line of code plots the observed rank sum on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "plt.scatter(prioleau_colts_sum, 0, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2e) The Decision ###\n",
    "Compute the $P$-value of the test. This is an exact $P$-value, not an empirical or numerical approximation.\n",
    "\n",
    "Recall that the $P$-value is the probability, assuming the null hypothesis is true, of observing a statistic that is equal to the one in our sample or even more in the direction of the alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "What is your decision, based on the test? Which of the two hypotheses do you think is better supported by the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Part A of the lab ends here, and is due by 11:59 pm Monday October 12 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage\n",
    "\n",
    "## Part 3: Normal Curves ##\n",
    "The probability distribution of the rank sum statistic looks very much like the normal curve, but not exactly. For example, look at the peak of the curve. You will see two flat bits on either side. \n",
    "\n",
    "Still, the distribution doesn't look too far from normal, so it is worth reminding ourselves about the normal curve. This part of the lab takes you quickly through some code that you can use to display normal curves and areas under them, and also to find numerical values of the areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3a) Plotting the Curve ###\n",
    "The equation of this curve is one of the greatest hits of probability theory, mathematics, and statistics. Here it is, though you will not need it for the lab. Of course we will have a lot to do with it later in Prob 140.\n",
    "\n",
    "The parameters of the curve are a \"center\" $\\mu$ that can be any number, and a \"spread\" $\\sigma$ that is a positive number. The equation is\n",
    "\n",
    "$$\n",
    "f(x) ~ = ~ \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}\\big{(}\\frac{x-\\mu}{\\sigma}\\big{)}^2}, ~~~~~~~ -\\infty < x < \\infty\n",
    "$$\n",
    "\n",
    "The relation of $\\mu$ and $\\sigma$ to the expectations and variances that we have been studying in class will become more evident as you go through the lab.\n",
    "\n",
    "To plot the curve, use the `prob140` function `Plot_norm` with three arguments:\n",
    "- the interval of values of $x$ over which to plot the curve\n",
    "- the \"center\" of the curve, which is $\\mu$\n",
    "- the \"spread\" of the curve, which is $\\sigma$\n",
    "\n",
    "The curve corresponding to $\\mu = 0$ and $\\sigma = 1$ is called the *standard normal curve*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot_norm((-4, 4), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot_norm((56, 80), 68, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "You can see that the two are just the same curve, apart from labels on the axes. \n",
    "\n",
    "We will prove later in the term that the total area under the normal curve is 100%. You can therefore think of the curve as a continuous approximation to a discrete histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3b) Areas Under the Curve ###\n",
    "As you know, for a discrete random variable the cumulative distribution function (cdf) at a point is the area under the probability histogram to the left of that point. The cdf of the normal curve is defined analogously.\n",
    "\n",
    "The gold area below is the value of the cdf of the standard normal curve at the point $x = 2$. Notice the use of `right_end = 2` to color the area; when the left end is not specified, it is assumed to be the leftmost value on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot_norm((-4, 4), 0, 1, right_end = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The numerical value of the area is found by `stats.norm.cdf` with the arguments $x$, $\\mu$, and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "stats.norm.cdf(2, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Find the numerical value of the area below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot_norm((56, 80), 68, 3, left_end = 65, right_end = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage\n",
    "\n",
    "## Part 4: Normal Approximation ##\n",
    "To use a normal curve to approximate a distribution, you must first identify the two parameters of the curve. For reasons that are not surprising and will become precise later in the course, the right parameters are the expectation and SD of the distribution being approximated.\n",
    "\n",
    "Let's find the normal curve that approximates the distribution of the rank sum statistic in Part 2. Why approximate a distribution we already know exactly? The answer is that we will need the method of approximation when the sample sizes are too large for us to be able to enumerate all possible samples. Finding the approximation in a case where we know the exact answer helps us see that the approximation is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4a) Expectation and SD Under the Null ###\n",
    "Under the null hypothesis of random selection, the distribution of our rank sum statistic is the distribution of the sum of a simple random sample of size 4 from the population of integers 1 through 15.\n",
    "\n",
    "In general, let $W$ be the sum of  $n$ ranks drawn at random without replacement from the integers 1 through $N$.\n",
    "\n",
    "Refer to [Sections 12.1](http://prob140.org/textbook/Chapter_12/01_Definition.html) and [13.3](http://prob140.org/textbook/Chapter_13/03_Sums_of_Simple_Random_Samples.html) of the textbook for the formulas that you need in order to define the functions below. \n",
    "\n",
    "Define a function `ev_ranksum` that takes $n$ and $N$ as its arguments and returns $E(W)$. **Do not** use arrays or `np.average` in your definition. Use the formulas derived in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def ev_ranksum(n, N):\n",
    "    return ...\n",
    "\n",
    "null_expectation = ev_ranksum(4, 15)\n",
    "null_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now define a function `sd_ranksum` that takes $n$ and $N$ as arguments and returns $SD(W)$. **Do not** use arrays or `np.std` in your definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def sd_ranksum(n, N):\n",
    "    return ...\n",
    "\n",
    "null_sd = sd_ranksum(4, 15)\n",
    "null_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To check your numerical answers, remember that you enumerated every possible sample and hence every possible rank sum. Run the cell below and confirm that its output is the same as the values returned by your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "np.average(rank_sums), np.std(rank_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4b) Superposing the Approximating Curve ###\n",
    "Re-use both lines of code in the last cell of 2d, and use Plot_norm appropriately to superpose the approximating normal curve over the histogram. Ignore the last line in the cell. It just sets a vertical scale so you can see all the different aspects of the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "Plot_norm...\n",
    "plt.ylim(-0.01, 0.06);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "You can see that the curve overestimates near the center, then underestimates on both sides, and then overestimates again in the tails. But it's not bad. The approximation typically improves when the sample sizes get larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage\n",
    "\n",
    "## Part 5: Continuity Correction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "In **2e** you found the exact $P$-value of the test of whether the four Colts ranks are too low to resemble a random sample of ranks. The graph above indicates that it should be possible to find an approximation to that chance using the normal curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 5a) Normal Approximation, First Attempt ###\n",
    "Use `stats.norm.cdf` to approximate the $P$-value. You will need quantities you defined in Part 4 as well as `prioleau_colts_sum` from Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Notice that the answer isn't quite what you got in **2e**. A common recommendation for small samples is that you either get an exact $P$-value as you did in Part 2 or use the normal approximation *with continuity correction*. The correction takes into account the fact that you are using a continuous curve to approximate a histogram consisting of rectangular bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 5b) Continuity Correction ###\n",
    "The correction is easier to see in the context of the binomial $(100, 1/2)$ histogram, that is, the distribution of the number of heads in 100 tosses of a coin. \n",
    "\n",
    "Look up [Section 13.2](http://prob140.org/textbook/Chapter_13/02_Sums_of_IID_Samples.html) of the textbook for the expectation and SD of the number of heads. Enter them below to draw the normal curve superposed on the binomial histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "b100 = stats.binom.pmf(np.arange(101), 100, 0.5)\n",
    "coins100 = Table().values(range(101)).probabilities(b100)\n",
    "\n",
    "Plot(coins100, edges=True)\n",
    "Plot_norm((34.5, 65.5), ...)\n",
    "plt.xlim(34.5, 65.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The normal approximation is excellent and doesn't systematically overestimate or underestimate. The exact chances, of course are the areas of the bars of the histogram.\n",
    "\n",
    "Let $X$ be the number of heads in 100 tosses. The blue area below is the exact value of $P(45 \\le X \\le 55)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot(coins100, edges=True)\n",
    "plt.xlim(44.5, 55.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Find the numerical value of $P(45 \\le X \\le 55)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "sum(stats.binom...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Here is the area again, but this time we have superposed the normal curve and colored the area under the curve between 45 and 55. The color is gold, as you can see between the bars and the curve. The purplish shade is due to the overlap between the gold and the blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "Plot(coins100, edges=True)\n",
    "Plot_norm((43.5, 56.5), 50, 5, left_end=45, right_end=55)\n",
    "plt.xlim(44.5, 55.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Is the colored area under the curve (purple plus gold) a good approximation to $P(45 \\le X \\le 55)$? If not, what is the main problem with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Correct the problem, that is, make the *continuity correction*, by completing the cell below. Make sure to only edit `left_end` and `right_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "Plot(coins100, edges=True)\n",
    "Plot_norm((43.5, 56.5), 50, 5, left_end = ..., right_end = ...)\n",
    "plt.xlim(44.5, 55.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use `stats.norm.cdf` to find the colored area under the normal curve above, and compare with the exact answer you got earlier in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 5c) Normal Approximation with Continuity Correction ###\n",
    "Now revisit **5a** and **2e**, and use the continuity correction in the normal approximation to the $P$-value. Compare with the exact value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Look again at the graph in **4b**. The normal curve won't do a good job at approximating probabilities of intervals around the center, with or without continuity correction. Indeed, you can easily find intervals where using the continuity correction is worse than not using it. \n",
    "\n",
    "We have the exact distribution of the statistic, so we should just use that. The normal approximation is better when the samples are large, which is also when it is intractable to find the exact distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Conclusion ##\n",
    "What you have learned:\n",
    "- A rank-based method for inference\n",
    "- How to enumerate all possible simple random samples to get the sampling distribution of a statistic\n",
    "- Applications of expectation and SD formulas derived in class, for comparing two samples\n",
    "- Mechanics of the normal approximation to discrete distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Submission Instructions ##\n",
    "\n",
    "Many assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions. \n",
    "\n",
    "### Written Portion ###\n",
    "*  Scan all the pages into a PDF. You can use any scanner or mobile application. There are many free apps available that allow you to convert your work into PDFs from your phone. Please **DO NOT** simply take pictures using your phone. \n",
    "* Please start a new page for each question. If you have already written multiple questions on the same page, you can crop the image or fold your page over (the old-fashioned way). This helps expedite grading.\n",
    "* It is your responsibility to check that all the work on all the scanned pages is legible.\n",
    "\n",
    "### Code Portion ###\n",
    "* Save your notebook using File > Save and Checkpoint.\n",
    "* Generate a PDF file using File > Download as > PDF via LaTeX. This might take a few seconds and will automatically download a PDF version of this notebook.\n",
    "    * If you have issues, please make a follow-up post on the general Lab 5 Piazza thread.\n",
    "    \n",
    "### Submitting ###\n",
    "* Combine the PDFs from the written and code portions into one PDF.  [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so. \n",
    "* Submit the assignment to Lab 4A and Lab 4B on Gradescope. \n",
    "* **Make sure to assign each page of your pdf to the correct question.**\n",
    "* **It is your responsibility to verify that all of your work shows up in your final PDF submission.**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "checksums": [
   "f55a7e1c90e2595b233c3956a2783786",
   "50a07c14da72c6c483f10d47657ed98d",
   "a8262e86df16c882ee2427d96fb7224f",
   "daea4c5fc1179387e84bfb78d69aa285",
   "518c84f8a1f148dbd174743a2ce02a06",
   "95aabe1c8dcd2f70513d7a7ba2cd3d7f",
   "bb46600c31715ec33415dab714607f0a",
   "6295b23dbaf751cb29ea9b92e1279348",
   "ceba9b895d874739554c04e75ac0f158",
   "b632a396eaad335105e52d833a50dd06",
   "c0383a53f086be33a25cf05004424e28",
   "47e82ade0793d076800618c1b0fac378",
   "af31f3bec266400c95b30eb302a818ed",
   "ba9abad2f9276f1a09777cbe3161e0b5",
   "d9c521f97f84c0a1adce153a07fb7e9f",
   "59adc2539c59f06dd3b31ac388fdb197",
   "91fd0556b2b58c1591a20c1c4454f949",
   "c20e2f4c4e155c0910908f0501f97331",
   "06e6273d635548cb1acb14f0cb877830",
   "7580e157277642310de11f21b3f4a2aa",
   "22c2439855fe463912e8f8f624f03896",
   "ef6b41e3f5eb75103f8a8082e926b0b6",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "eaf3202cab97c787d5e74402770b56f4",
   "5a5216f1f21e8c565e5b731f62e3e607",
   "bc0a2735f52fe3ff5d96d5574ab815d7",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "fe344393784a08713ce88aa02baafcaf",
   "c8217143b8008b7b193b616e5425f8a6",
   "30e10b65c029f0ef85e0fad01ed13e9c",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "400d1f48c28c18836b9f0e2a826c5a5f",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "fa18736546b3251060c88573c05ddc86",
   "9b6f9970f1c3fa2feebbaad5f7c04358",
   "b06dcfed229ebacf5c2f63cf69eaa7c1",
   "923b836f44407a1daa6a3a356e2cd13c",
   "8ec599a5a74924b9215af74742625e49",
   "88b436150facb84a21b4137cf028c4cc",
   "765c06fb0a2fa9ec54c5d0c814260c90",
   "e3b216a45ea521dc2d2e12074fbfaecb",
   "1c7cd2431e1a95d1778371daa800f3df",
   "99747f3be2369a794b8d5b6f4622d7db",
   "ac5d63fd97e55780b39d53ae44b31977",
   "e4699c22cb5ba6e3bea407fb0e5369bf",
   "7a8a66650c8c03b13f81c7a33c72f13c",
   "5a6fb3fd47e24e04faa1935129400d22",
   "84e3f129d2facf258856470f2df8680d",
   "2f43b42fd833d1e77420a8dae7419000",
   "101908f928367c553d43260893bc385e",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "ee540feffb1a76041a6927ccdec2580b",
   "68e17f22a6b85756a6a3fc14059fa660",
   "7bb515af8465ea4134ee8634d3b7fc99",
   "64d0d78fb3d67bc0b84e2e147215e08c",
   "17145de266a5be501cd5a69080aae537",
   "2f0c718408414a5a3d676b8f834b192d",
   "091204ef93a98c9dc350e9e7c5d9a889",
   "7368a874359fc4bc3dce15e2cec52bb1",
   "158551049de3937a05ab48a3042467bc",
   "b72077b2742b15ebdce9806413a84391",
   "42e5733ac5e255c212442e34ebaee9d9",
   "cff3fc401edc86f60cc9901efbbbd1ef",
   "2f43b42fd833d1e77420a8dae7419000",
   "2dcbf4a841420f2b5268a5810834f2a1",
   "643085619bfdf358ccc2f0ff69f7757e",
   "5c31207bc52b57ec1385fb8de2f904a2",
   "35676a73987dbfdd360049d60008899b",
   "ba53744a20f40a756dff2f5478a60177",
   "f863bd360de62a1a4c7b1e1befd77cb6",
   "adf1106410441d2233370f59f9c5883c",
   "daf2c7c732a5e83b6d256b0c809ad7e2",
   "d71a4d62086c93387f6a9279ade17b2a",
   "c845e51f2354c3bff150f224f07740b3",
   "cf3db7ad30da7cb65818d5a7ae6b3ab8",
   "69ccae2a33990d5efc956142b3a90557",
   "9fe17d864503edbfb0c244b84696e824",
   "2f43b42fd833d1e77420a8dae7419000",
   "47d071f12ec5866f36d1a63a3f726b92",
   "cdc235a480aa349ecfdb46e1e60385a4",
   "db1b520be6bbf970e98551d9773a3346",
   "6914070cae66cb049f9fe4fab81d2a6d",
   "a17faffcf8067dee60735153de7293ad",
   "0c7246824d519c52de1043447f24f897",
   "424f7f7df843772d36b0cdb610054d87",
   "0463166824014f6fbb4bc07c3736d0ac",
   "998dd5ce2980adf517ca993e42c3d965",
   "75fd00abac5701d1d5a6a1adf6c89013",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "c3cd1927f4be9d5787994c7545159e70",
   "cf11ea263021d7007f178f07d657e149",
   "54e5c75bf21e767282ceb82c5402761d",
   "2f43b42fd833d1e77420a8dae7419000",
   "17f64fbb22e6edea8681381d2d5a2440",
   "2f43b42fd833d1e77420a8dae7419000",
   "396345d0af525f363c500f4d50e6850b",
   "f9bd54f7f5343e073421186aa18770ce",
   "5f4051bb4c07372add1c16a5884fefb6"
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "number_of_pagebreaks": 5
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
